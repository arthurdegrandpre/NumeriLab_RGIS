---
title: "NumeriLab; R maps and GIS"
author: "Arthur de Grandpré"
date: "25 janvier 2019"
output: 
  html_document:
    keep_md: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Context

Most would agree that data science should always start and end with data visualization. It allows the scientist to understand the data, its structure and distribution, but also to connect with the public, by creating easily understandable content to facilitate communication. 

In the previous workshops, we have learned how to:   
- Efficiently visualize data and results  
- Manipulate Data to facilitate its analysis  
- Generate data efficiently in order to replicate real life trends  
  
... and all of this makes it hard to leave the R environment! Still, most of us still are leaving the comfort of R whenever we are faced with spatial data, splitting our workflow and creating different codes, different processes and ultimately resulting in a loss of time and efficiency.  
  
While R still can't fully replace a full GIS suit, it is able to perform most tasks that are required on an almost daily basis for people working with spatial data.

  
## R as a GIS and Mapping Software

To address this problem, multiple libraries have been made available in R in order to deal with spatial data, its visualisation, its manipulation and its analysis.
the most notable are probably:


**GIS**  
sp : allow the creation and manipulation of spatial objects (spatialpointsdataframes) + apply CRS and stransformations
sf : alternative environment to sp, uses different objects but works in very similar ways
rgdal : An interface to access gdal, a spatial data processing library  
rgeos : An interface to access geos, a spatial vector data processing library 

**mapping**  
base R : plot() can do most of the job, but we can get much better!  
ggplot2 : still able to do most of the job, but prettier  
ggmap : extends ggplot2 mapping functionalities and enables to retrieve google style static maps, requires API for most applications  
ggsn : adds scale bars and north arrows to ggmap
leaflet : allows to build interactive maps, google map style, easy to share  
ggsn : for on map scale and north arrow, but might not work as expected  
  
**other useful packages**  
tmap ; raster ; spdep ; cartography ; maptools ; gstat
  
## Goals of the workshop

The main goal of this workshop is to break the mindset in which R is unable to deal with spatial data or spatial analysis.  
It is important to keep in mind that this is *only an introduction* and that it is possible to do almost anything on R, and in *many different ways*.  
Also, it might be even more important to keep in mind that in many situations, while R *could* do it, you might want to consider other solutions. Using R for everything is fun and can be practical, but sometimes it's just more tedious than necessary.
  
By the end of this workshop, I wish that frequent GIS tasks do not feel intimidating for those who attended, such as:    

- reading and visualising point data  
- transforming the CRS from data  
- loading a basemap from the internet  
- reading and visualising a vector file  
- reading and visualising a raster file  
- making and sharing simple maps
- clipping a raster with a polygon
- sharing an html map including layers control

  A second workshop will focus on more advanced features to work with rasters such as remote sensing imagery, introducing methods such as:
  
- running an unsupervised classification
- comparing vegetation indexes (NDVI)
- obtaining zonal statistics on buffers
- obtaining landscape metrics

## Exercice:

note: all data for this exercise is located in the repository under the "Data" sub-directories

#**Step 1.** Prepare R environment and load the libraries
```{r packages installation , eval=FALSE, include=FALSE}
install.packages("sp")
install.packages("rgdal")
install.packages("ggplot2")
install.packages("ggmap")
install.packages("ggsn")
install.packages("leaflet")
install.packages("mapview")
webshot::install_phantomjs()
install.packages("raster")
install.packages("cluster")
install.packages("SDMTools")
install.packages("rgeos")
install.packages("htmlwidgets")
```


```{r preparation, message=F, warning=F}
rm(list=ls())

library(sp) # for functions coordinates, proj4string, CRS
library(rgdal) # for functions readOGR
library(ggmap)
library(ggsn) #scalebar and north arrow for ggplot and ggmap
library(leaflet)
library(mapview)#; webshot::install_phantomjs() has to be run only once
library(tidyverse)

library(raster) # for functions raster, plotRGB#library(rgeos)
library(cluster)
library(SDMTools)
library(rgeos)
library(htmlwidgets)
```

**Step 2.** reading and visualising point data + adding a *Google* type basemap

Multiples solutions are available to read point data in the R environment depending on your database format. The most common data format is text, such as .csv files. When working with .csv files, you will often have two columns referring to the coordinates of your data, which can be used create a spatial object with the package *sp*.  
  
If you have a shapefile of your data, it will be imported directly as a spatial object by using the function readOGR() from the *rgdal* package

```{r reading point data}
df = read.csv("Data/csv/data_picom_HT.csv",sep=";")
# this text file contains x and y coordinates and a random associated value
class(df)
head(df)
```

Help sheet for CRS selection in *rgdal* and *sp* @ https://www.nceas.ucsb.edu/~frazier/RSpatialGuides/OverviewCoordinateReferenceSystems.pdf

```{r spatial object and CRS}
coordinates(df) = c("long","lat")
class(df) # at this point R recognizes the data as a spatial object
proj4string(df) = CRS("+init=epsg:4269") #this allows to specify the data CRS is NAD83
```

At this point, we have the same output as if we had used the function readOGR from rgdal to read a shapefile of the same information

```{r summary of spatialpointsdataframe}
summary(df)
```

It is very easy to transform the CRS of an object by using the spTransform function. it can be done my manually entering the datum, ellipsoid and projection, but the simplest way is to just feed the epsg code to the function. epsg codes are unique identifiers for CRS and can be bound easily on internet.

```{r sptransform}
df <- spTransform(df, CRS("+init=epsg:4326"))  # transform to wgs84
summary(df)

```

at this point, the dataframe can be plotted in base R for visualisation...

```{r base r plot}
plot(df)
```

..and made into a simple plot for visualisation.

```{r base r plot 2}
plot(df,
     main="data points",
     axes=T,
     pch=21,
     bg=rev(heat.colors(5))[cut(df$tot_drymass,breaks=c(0,5000,7500,10000,12500,25000), labels = F)])
```

and the same can be done using ggplot2:

```{r ggplot}
ggplot()+
  geom_point(data=as.data.frame(df), aes(long,lat, fill=tot_drymass), shape=21, size=2)+
  scale_fill_gradientn(colours=rev(heat.colors(5)))+
  ggtitle("data points")

```

So we can now see that we have spatial points with some values, but that doesn't give us much of an idea of what they are and their context. For adding context, a basemap is really important. 

*Note*: Until recently, get_map from the package ggmap allowed to easily obtain basemaps from google and OpenStreetMaps. Sadly, google now requires an API key and billing information to access the basemaps, and it also broke the access to open access maps such as stamen. That makes loading a static basemap a bit harder.  
While it is still possible to access google maps and OpenStreetMaps, it is required to register an API key (generally free to obtain, but requires registration)  
  
https://www.r-bloggers.com/geocoding-with-ggmap-and-the-google-api/ for google API

```{r basemap, message=F}

map = get_stamenmap(bbox=bbox(df),
                  zoom=17,
                  crop=F,
                  maptype = "toner-lite")
ggmap(map)
# other basemap types from stamen:
#“terrain”, “terrain-background”, “terrain-labels”, “terrain-lines”, “toner”, “toner-2010”, “toner-2011”, “toner-background”, “toner-hybrid”, “toner-labels”, “toner-lines”, “toner-lite”, “watercolor”
```


Using the basemap, it's possible to plot the points with a lot more information. Also, using the *ggsn* library, we can add a north arrow and a scale bar to ggmap. (For unknown reasons the scale bar did not work here so it was removed)
```{r ggmap and ggsn}
map2 = ggmap(map)+
  blank()+
  geom_point(data=as.data.frame(df), aes(long,lat, fill=tot_drymass), shape=21, size=2)+
  scale_fill_gradientn(colours=rev(heat.colors(5)))+
  ggtitle("data points") +
  coord_equal(1.4) +
  north(df,
        location="topright") 
map2
ggsave("Figures/ggmap1.png")

```

Luckily, leaflet still does this very good for interactive maps.  
By default, leaflet uses OpenStreetMap

```{r}
# using the default values, leaflet uses OpenStreetMap
leaflet(df) %>%
  addTiles()

```

But it can be set to call other data sources, including google if an API key is registered.

```{r}
leaflet(df) %>%
  addProviderTiles("Stamen.Toner")

```

It possesses different types of markers, such as pins.

```{r}

leaflet(df) %>%
  addTiles() %>%
  addMarkers()

```

Or circles.

```{r}

leaflet(df) %>%
  addTiles() %>%
  addCircleMarkers()

```

And those can be customized to display data values with continuous scales

```{r}

pal = colorNumeric(
  palette = "RdYlGn",
  domain = df$tot_drymass
)

leaflet(df) %>%
  addTiles() %>%
  addCircleMarkers(color = "black", opacity=1, fillColor=~pal(tot_drymass), fillOpacity = 0.5, radius=8) %>%
  addLegend("bottomright",
            pal=pal,
            values=~tot_drymass,
            title= "drymass (kg / 0.04 ha")

```

Or by quantiles

```{r}

qpal = colorQuantile("RdYlGn", df$tot_drymass, n = 4)

leaflet(df) %>%
  addTiles() %>%
  addCircleMarkers(color = "black", opacity=1, fillColor=~qpal(tot_drymass), fillOpacity = 0.5, radius=8) %>%
  addLegend("bottomright",
            pal=qpal,
            values=~tot_drymass,
            title= "Drymass Quantile") %>%
  addScaleBar(position="bottomleft")

```

And their size can also be fixed to represent the size of a variable

```{r}
leaflet(df) %>%
  addTiles() %>%
  addCircles(color = "black", opacity=0.5, fillColor=~pal(tot_drymass), fillOpacity = 0.8, radius=df$n_trees) %>%
  addLegend("bottomright",
            pal=qpal,
            values=~tot_drymass,
            title= "Drymass Quantile") %>%
  addScaleBar(position="bottomleft")
```


And then this map can be saved to a png or jpg format using the *mapview* package

```{r}
m1 = leaflet(df) %>%
  addTiles() %>%
  addCircles(stroke=F, opacity=1, fillColor=~pal(df$tot_drymass), fillOpacity = 0.8, radius=df$n_trees) %>%
  addLegend("bottomright",
            pal=qpal,
            values=~df$tot_drymass,
            title= "values") %>%
  addScaleBar()

m1

mapshot(m1, file= "Figures/m1.png")

```

#**Step 2.** Loading and plotting vectors and rasters

often, we have polygons delimiting zones of interest for our data. they can be used for visualisation, but also in data analysis.

```{r}
##adding polygon
campus = readOGR("Data/shapefiles/campus polygon.shp")
campus = spTransform(campus, CRS("+init=epsg:4326"))
campus


leaflet(df) %>%
  addTiles() %>%
  addCircles(stroke=F, opacity=1, fillColor=~pal(df$tot_drymass), fillOpacity = 0.8, radius=df$n_trees) %>%
  addLegend("bottomright",
            pal=qpal,
            values=~df$tot_drymass,
            title= "values") %>%
  addScaleBar() %>%
  addPolygons(data=campus, stroke=T, fillOpacity = 0)

```

When working with spatial data, it can often be useful to access remote sensing data to perform different types of analysis.

the rest of the workshop will be mostly about working with such data in R, based on a sample of Sentinel-2 imagery.

Then, let's load some data raster data that we can work with.
To do so, the package "raster" contains most of the basic functions required for R to read and manage rasters. A raster is basically a spatially referenced matrix. where every value is associated with a spatial extent (resolution) and a coordinate taken from a georeference system (ex: WGS84).

```{r loading and plotting rasters}

# The raster function allows to read the most common raster formats, such as .TIFF
tr_r = raster("./Data/S2/True color.tiff")

# base R has some functions that allow for plotting of rasters
plot(tr_r, main="UQTR on 2018-09-13, Sentinel-2")
# something seems quite wrong with the colour, so let's inspect our raster
tr_r

```

```{r}

# it seems we only have access to one of the 3 layers contained in tr_r. This is because the raster function is programmed to create a single layer object.
# still, we can look into better ways of diplaying this single band, such as grayscale
grayscale_colors = gray.colors(100,
                               start= 0.0,
                               end=1,
                               gamma=2.2,
                               alpha=NULL)
plot(tr_r, main="UQTR on 2018-09-13, red band grayscale, Sentinel-2", col=grayscale_colors)

```

```{r}

# or load another band from the same source
tr_r2=raster("./Data/s2/True color.tiff", band=2)
tr_r2 # this shows we are now using band 2 of 3 instead of 1

```

```{r}
# we need to use the brick function to create a RasterBrick, composed of multiple raster layers
tr_r = brick("./Data/s2/True color.tiff")
tr_r # we do have our 3 layers

tr_r=addLayer(tr_r, "Data/s2/B08.tiff")

tr_r=projectRaster(tr_r, crs=("+init=epsg:4326"))
plot(tr_r, col=grayscale_colors, main="UQTR on 2018-09-13, grayscale, Sentinel=2") # but the plot function does not plot them together. To do so, we need to specify each color bands, or use the function plotRGB
hist(tr_r)
plotRGB(tr_r, r=1,g=2,b=3,stretch="hist")
dev.off()
```


It's not yet possible to add composite rasters in leaflet (such as RGB). to include true color raster, we need to add it using the mapview package and the viewRGB function. It does not allow to work the layer control in the same way.

```{r}

viewRGB(tr_r, 1,2,3, map=m1, quantiles = c(0.05, 0.95))

```

when multiple bands are available, it becomes possible to easily perform raster maths, allowing to obtain different indexes, such as NDVI

```{r}

tr_r$NDVI=(tr_r$B08-tr_r$True_color.1)/(tr_r$B08+tr_r$True_color.1)
plot(tr_r$NDVI)

```

it is also possible to limit the extent of the satellite data to our zone of interest as delimited by our campus polygon

```{r}

crop_tr=mask(tr_r,campus)
plot(crop_tr$NDVI)

```

from there, we can visualise the campus NDVI values back into the leaflet environment.

```{r}

val = as.numeric(c(0:1))
pal = colorNumeric(c("red","yellow","green"), val, na.color="transparent")
                 
ndvi_map=leaflet(df) %>%
  addTiles() %>%
  addRasterImage(crop_tr$NDVI, colors = pal , opacity = 0.3) %>%
  addLegend(pal = pal, values = val, title = "NDVI") %>%
  addCircles(color="black", opacity = 1, stroke=T)
ndvi_map

```

since we have many data points scattered around campus that already have a lot of information, it can be interesting to add some remote sensing data to our data frame. That allows us to look at many types of interesting relations in the data.

# **Step 3.** extracting data from rasters
```{r ndvi zonal stats from extract function}

mean_ndvi = extract(crop_tr$NDVI, df, buffer=10, small=T, fun=mean)
sd_ndvi = extract(crop_tr$NDVI, df, buffer=10, small=T, fun=sd)

?extract
df$ndvi=mean_ndvi
df$ndvi_sd=sd_ndvi

plot(df$ndvi~df$aerial_drymass)
plot(df$ndvi~df$est_age)
plot(df$ndvi~df$dom_sp)
plot(df$ndvi~df$zone_eco)

```

Now that we know how to display and manipulate spatial data, let's put it into a nice shareable format and save it.
To do so, let's redefine our colours and add layer control, then let's save the map into an html object.

# **Step 4.** Sharing your awesome map
```{r}
        
ndvi_val = as.numeric(c(-1:1))
ndvi_pal = colorNumeric("RdYlGn",
                        ndvi_val,
                        na.color = "transparent")

circ_pal = colorNumeric("viridis",
                        df$total_drymass)

map = leaflet(df) %>% 
  addScaleBar("bottomleft") %>% 
  addTiles(group = "BaseOSM") %>%
  addProviderTiles("Stamen.Toner",
                   group = "BaseStamen") %>% 
  addRasterImage(crop_tr$NDVI,
                 colors = ndvi_pal,
                 opacity = 0.6,
                 group = "NDVI") %>%
  addLegend("bottomright",
            pal = ndvi_pal,
            values = ndvi_val,
            title = "NDVI",
            group = "NDVI") %>% 
  addCircles(color = "black",
             opacity = 0.5,
             fillColor = ~circ_pal(tot_drymass),
             fillOpacity = 0.8,
             radius = df$n_trees,
             group = "drymass",
             stroke = F,
             popup = paste("n Trees:", df$n_trees, "<br>",
                           "DHP:", df$mean_dhp)) %>% 
  addLegend("bottomright",
            pal = circ_pal,
            values = ~tot_drymass,
            title = "drymass (kg / 0.04 ha)",
            group ="drymass") %>% 
  addLayersControl("bottomleft",
    baseGroups = c("BaseOSM","BaseStamen"),
    overlayGroups = c("NDVI","drymass")
  )
map
  
saveWidget(map, file="map.html", selfcontained = T)

```

# **Step 5.** Sharing spatial data

There are many ways to share spatial data without loosing it's spatial properties (CRS, for exemple).

The classics are the shapefiles, but they are clunky and require multiple files. Alternatives include the GeoJSON format, and more recently, geopackage (GPKG, which is also faster)

```{r write geopackage}

writeOGR(df, "Data/out_df.gpkg","campus_trees",driver="GPKG", overwrite_layer = T)

test = readOGR("Data/out_df.gpkg")
test
```


# extras
tutorials:  
https://www.neonscience.org/dc-multiband-rasters-r  
-https://cran.r-project.org/doc/contrib/intro-spatial-rl.pdf  
-https://pakillo.github.io/R-GIS-tutorial/  
-http://www.nickeubank.com/gis-in-r/  
-http://remi-daigle.github.io/GIS_mapping_in_R/  
-https://www.r-bloggers.com/using-r-as-a-gis/  

cheat sheets:  
-https://www.maths.lancs.ac.uk/~rowlings/Teaching/UseR2012/cheatsheet.html  
-http://www.nickeubank.com/wp-content/uploads/2015/10/gis_in_r_raster_cheatsheet.pdf  
-http://www.nickeubank.com/wp-content/uploads/2015/10/gis_in_r_vector_cheatsheet.pdf  
  







